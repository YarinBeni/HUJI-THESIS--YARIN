{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Akkadian Data Exploration\n",
        "\n",
        "This notebook explores the Akkadian text data provided by Shahar Spencer.\n",
        "\n",
        "## Data Sources:\n",
        "- **eBL (Electronic Babylonian Library)**: ~28,000 fragments in `full_corpus_dir/`\n",
        "- **Filtered JSON files**: Raw source data in `filtered_json_files/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "sns.set_style('whitegrid')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data directory exists: True\n",
            "Corpus directory exists: True\n"
          ]
        }
      ],
      "source": [
        "# Define paths\n",
        "data_dir = Path('../data/downloaded')\n",
        "full_corpus_dir = data_dir / 'full_corpus_dir'\n",
        "\n",
        "# Check if directory exists\n",
        "print(f\"Data directory exists: {data_dir.exists()}\")\n",
        "print(f\"Corpus directory exists: {full_corpus_dir.exists()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Count Available Fragments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of fragment files: 28194\n",
            "\n",
            "First 5 files:\n",
            "  EBL_1881,0727.111.csv\n",
            "  EBL_K.11322.csv\n",
            "  EBL_BM.134828.csv\n",
            "  EBL_NBC.5298.csv\n",
            "  EBL_K.18460.csv\n"
          ]
        }
      ],
      "source": [
        "# Get all CSV files\n",
        "csv_files = list(full_corpus_dir.glob('*.csv'))\n",
        "print(f\"Total number of fragment files: {len(csv_files)}\")\n",
        "\n",
        "# Show first 5 filenames\n",
        "print(\"\\nFirst 5 files:\")\n",
        "for f in csv_files[:5]:\n",
        "    print(f\"  {f.name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load and Inspect a Single Fragment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fragment: EBL_1881,0727.111.csv\n",
            "Shape: (10, 10)\n",
            "\n",
            "Columns: ['fragment_id', 'fragment_line_num', 'index_in_line', 'word_language', 'value', 'clean_value', 'lemma', 'domain', 'place_discovery', 'place_composition']\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fragment_id</th>\n",
              "      <th>fragment_line_num</th>\n",
              "      <th>index_in_line</th>\n",
              "      <th>word_language</th>\n",
              "      <th>value</th>\n",
              "      <th>clean_value</th>\n",
              "      <th>lemma</th>\n",
              "      <th>domain</th>\n",
              "      <th>place_discovery</th>\n",
              "      <th>place_composition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1881,0727.111</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>AKKADIAN</td>\n",
              "      <td>SAG.DU-su</td>\n",
              "      <td>SAG.DU-su</td>\n",
              "      <td>['qaqqadu I']</td>\n",
              "      <td>['CANONICAL ➝ Technical ➝ Ritual texts']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1881,0727.111</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>AKKADIAN</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>[]</td>\n",
              "      <td>['CANONICAL ➝ Technical ➝ Ritual texts']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1881,0727.111</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>AKKADIAN</td>\n",
              "      <td>šu₂</td>\n",
              "      <td>šu₂</td>\n",
              "      <td>['-šu I']</td>\n",
              "      <td>['CANONICAL ➝ Technical ➝ Ritual texts']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1881,0727.111</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>AKKADIAN</td>\n",
              "      <td>du</td>\n",
              "      <td>du</td>\n",
              "      <td>[]</td>\n",
              "      <td>['CANONICAL ➝ Technical ➝ Ritual texts']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1881,0727.111</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>AKKADIAN</td>\n",
              "      <td>an</td>\n",
              "      <td>an</td>\n",
              "      <td>[]</td>\n",
              "      <td>['CANONICAL ➝ Technical ➝ Ritual texts']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1881,0727.111</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>AKKADIAN</td>\n",
              "      <td>an</td>\n",
              "      <td>an</td>\n",
              "      <td>[]</td>\n",
              "      <td>['CANONICAL ➝ Technical ➝ Ritual texts']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1881,0727.111</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>AKKADIAN</td>\n",
              "      <td>EN₂</td>\n",
              "      <td>EN₂</td>\n",
              "      <td>['šiptu I']</td>\n",
              "      <td>['CANONICAL ➝ Technical ➝ Ritual texts']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1881,0727.111</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>AKKADIAN</td>\n",
              "      <td>u₃</td>\n",
              "      <td>u₃</td>\n",
              "      <td>['u I']</td>\n",
              "      <td>['CANONICAL ➝ Technical ➝ Ritual texts']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1881,0727.111</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>AKKADIAN</td>\n",
              "      <td>EN₂</td>\n",
              "      <td>EN₂</td>\n",
              "      <td>['šiptu I']</td>\n",
              "      <td>['CANONICAL ➝ Technical ➝ Ritual texts']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1881,0727.111</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>AKKADIAN</td>\n",
              "      <td>MIN</td>\n",
              "      <td>MIN</td>\n",
              "      <td>[]</td>\n",
              "      <td>['CANONICAL ➝ Technical ➝ Ritual texts']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     fragment_id  fragment_line_num  index_in_line word_language      value  \\\n",
              "0  1881,0727.111                  3              1      AKKADIAN  SAG.DU-su   \n",
              "1  1881,0727.111                  4              2      AKKADIAN          a   \n",
              "2  1881,0727.111                  4              3      AKKADIAN        šu₂   \n",
              "3  1881,0727.111                  5              1      AKKADIAN         du   \n",
              "4  1881,0727.111                 10              0      AKKADIAN         an   \n",
              "5  1881,0727.111                 10              1      AKKADIAN         an   \n",
              "6  1881,0727.111                 12              0      AKKADIAN        EN₂   \n",
              "7  1881,0727.111                 14              0      AKKADIAN         u₃   \n",
              "8  1881,0727.111                 16              0      AKKADIAN        EN₂   \n",
              "9  1881,0727.111                 18              0      AKKADIAN        MIN   \n",
              "\n",
              "  clean_value          lemma                                    domain  \\\n",
              "0   SAG.DU-su  ['qaqqadu I']  ['CANONICAL ➝ Technical ➝ Ritual texts']   \n",
              "1           a             []  ['CANONICAL ➝ Technical ➝ Ritual texts']   \n",
              "2         šu₂      ['-šu I']  ['CANONICAL ➝ Technical ➝ Ritual texts']   \n",
              "3          du             []  ['CANONICAL ➝ Technical ➝ Ritual texts']   \n",
              "4          an             []  ['CANONICAL ➝ Technical ➝ Ritual texts']   \n",
              "5          an             []  ['CANONICAL ➝ Technical ➝ Ritual texts']   \n",
              "6         EN₂    ['šiptu I']  ['CANONICAL ➝ Technical ➝ Ritual texts']   \n",
              "7          u₃        ['u I']  ['CANONICAL ➝ Technical ➝ Ritual texts']   \n",
              "8         EN₂    ['šiptu I']  ['CANONICAL ➝ Technical ➝ Ritual texts']   \n",
              "9         MIN             []  ['CANONICAL ➝ Technical ➝ Ritual texts']   \n",
              "\n",
              "   place_discovery  place_composition  \n",
              "0              NaN                NaN  \n",
              "1              NaN                NaN  \n",
              "2              NaN                NaN  \n",
              "3              NaN                NaN  \n",
              "4              NaN                NaN  \n",
              "5              NaN                NaN  \n",
              "6              NaN                NaN  \n",
              "7              NaN                NaN  \n",
              "8              NaN                NaN  \n",
              "9              NaN                NaN  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the first fragment as an example\n",
        "sample_file = csv_files[0]\n",
        "df_sample = pd.read_csv(sample_file, index_col=0)\n",
        "\n",
        "print(f\"Fragment: {sample_file.name}\")\n",
        "print(f\"Shape: {df_sample.shape}\")\n",
        "print(f\"\\nColumns: {list(df_sample.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df_sample.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Understand Fragment Structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fragment ID(s): ['1881,0727.111']\n",
            "\n",
            "Number of lines: 8\n",
            "Total words: 10\n",
            "\n",
            "Languages: {'AKKADIAN': 10}\n",
            "\n",
            "Domain: [\"['CANONICAL ➝ Technical ➝ Ritual texts']\"]\n"
          ]
        }
      ],
      "source": [
        "# Check unique values in key columns\n",
        "print(\"Fragment ID(s):\", df_sample['fragment_id'].unique())\n",
        "print(f\"\\nNumber of lines: {df_sample['fragment_line_num'].nunique()}\")\n",
        "print(f\"Total words: {len(df_sample)}\")\n",
        "print(f\"\\nLanguages: {df_sample['word_language'].value_counts().to_dict()}\")\n",
        "print(f\"\\nDomain: {df_sample['domain'].unique()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Reconstruct Text from Fragment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reconstructed text:\n",
            "\n",
            "Line 3: SAG.DU-su\n",
            "Line 4: a šu₂\n",
            "Line 5: du\n",
            "Line 10: an an\n",
            "Line 12: EN₂\n",
            "Line 14: u₃\n",
            "Line 16: EN₂\n",
            "Line 18: MIN\n"
          ]
        }
      ],
      "source": [
        "# Reconstruct the fragment text line by line\n",
        "def reconstruct_fragment_text(df, use_clean=True):\n",
        "    \"\"\"Reconstruct fragment text from dataframe.\"\"\"\n",
        "    value_col = 'clean_value' if use_clean else 'value'\n",
        "    lines = []\n",
        "    \n",
        "    for line_num in sorted(df['fragment_line_num'].unique()):\n",
        "        line_df = df[df['fragment_line_num'] == line_num].sort_values('index_in_line')\n",
        "        words = line_df[value_col].tolist()\n",
        "        lines.append(f\"Line {line_num}: {' '.join(words)}\")\n",
        "    \n",
        "    return lines\n",
        "\n",
        "# Show the reconstructed text\n",
        "text_lines = reconstruct_fragment_text(df_sample)\n",
        "print(\"Reconstructed text:\\n\")\n",
        "for line in text_lines:\n",
        "    print(line)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 100 fragments, Total shape: (3759, 10)\n"
          ]
        }
      ],
      "source": [
        "# Load first 100 fragments\n",
        "sample_size = 100\n",
        "dfs = []\n",
        "for csv_file in csv_files[:sample_size]:\n",
        "    df = pd.read_csv(csv_file, index_col=0)\n",
        "    dfs.append(df)\n",
        "df_combined = pd.concat(dfs, ignore_index=True)\n",
        "print(f\"Loaded {len(dfs)} fragments, Total shape: {df_combined.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Basic Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== DATA STATISTICS ===\n",
            "Total fragments: 100\n",
            "Total words: 3759\n",
            "\n",
            "=== LANGUAGE DISTRIBUTION ===\n",
            "word_language\n",
            "AKKADIAN    3502\n",
            "SUMERIAN     234\n",
            "EMESAL        23\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== TOP 10 DOMAINS ===\n",
            "domain\n",
            "[]                                                                                                   729\n",
            "see genres.json file                                                                                 617\n",
            "['CANONICAL ➝ Divination ➝ Celestial ➝ Enūma Anu Enlil ➝ Ištar (EAE 50–68)']                         520\n",
            "['CANONICAL ➝ Technical ➝ Astronomy ➝ Astronomical Diaries']                                         285\n",
            "[['ARCHIVAL', 'Letter', 'Extispicy Query']]                                                          188\n",
            "[['CANONICAL', 'Magic']]                                                                             138\n",
            "['CANONICAL ➝ Divination ➝ Celestial']                                                               124\n",
            "['CANONICAL ➝ Literature ➝ Hymns ➝ Divine']                                                          111\n",
            "['ARCHIVAL']                                                                                         102\n",
            "['CANONICAL ➝ Divination ➝ Extispicy ➝ Bārûtu ➝ 4. Padānu', 'CANONICAL ➝ Technical ➝ Commentary']     82\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"=== DATA STATISTICS ===\")\n",
        "print(f\"Total fragments: {df_combined['fragment_id'].nunique()}\")\n",
        "print(f\"Total words: {len(df_combined)}\")\n",
        "print(f\"\\n=== LANGUAGE DISTRIBUTION ===\")\n",
        "print(df_combined['word_language'].value_counts())\n",
        "print(f\"\\n=== TOP 10 DOMAINS ===\")\n",
        "print(df_combined['domain'].value_counts().head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Vocabulary Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akkadian words: 3502\n",
            "Unique clean values: 1430\n",
            "\n",
            "Top 20 most common words:\n",
            "  ina: 180\n",
            "  ana: 84\n",
            "  ša₂: 76\n",
            "  MIN: 64\n",
            "  DIŠ: 55\n",
            "  la: 53\n",
            "  u: 51\n",
            "  ŠA₃: 50\n",
            "  KUR: 45\n",
            "  LUGAL: 45\n",
            "  NU: 43\n",
            "  {d}MIN: 34\n",
            "  BE: 31\n",
            "  AN: 28\n",
            "  E₂: 25\n",
            "  IGI: 25\n",
            "  a-na: 23\n",
            "  LU₂: 18\n",
            "  GE₆: 18\n",
            "  GIM: 18\n"
          ]
        }
      ],
      "source": [
        "# Filter for Akkadian only\n",
        "df_akkadian = df_combined[df_combined['word_language'] == 'AKKADIAN']\n",
        "print(f\"Akkadian words: {len(df_akkadian)}\")\n",
        "print(f\"Unique clean values: {df_akkadian['clean_value'].nunique()}\")\n",
        "print(f\"\\nTop 20 most common words:\")\n",
        "for word, count in df_akkadian['clean_value'].value_counts().head(20).items():\n",
        "    print(f\"  {word}: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Next Steps\n",
        "\n",
        "Based on this exploration, we can decide what to do next with the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Load Multiple Fragments for Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Akkadian V1)",
      "language": "python",
      "name": "akkadian-v1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
